{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 8: Credit Card Fraud Detection\n",
    "\n",
    "This notebook tackles the problem of credit card fraud detection. This is a classic example of a machine learning problem with a **highly imbalanced dataset**, where the number of fraudulent transactions is far lower than the number of legitimate ones.\n",
    "\n",
    "The main focus of this project is to demonstrate a technique for handling this imbalance—specifically, **Random Undersampling**—and to evaluate the model using appropriate metrics like the **Precision-Recall Curve**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.datasets import fetch_datasets\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the dataset from imbalanced-learn\n",
    "fraud_data = fetch_datasets()['creditcard_fraud']\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(fraud_data.data, columns=[f'V{i+1}' for i in range(fraud_data.data.shape[1])])\n",
    "df['Class'] = fraud_data.target\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the class distribution\n",
    "class_counts = df['Class'].value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Visualize the imbalance\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Class', data=df)\n",
    "plt.title('Class Distribution (0: Legitimate, 1: Fraud)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset is extremely imbalanced. This is the core challenge we need to address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Splitting\n",
    "\n",
    "The features in this dataset are already scaled (they are the result of a PCA transformation). We just need to define our features (X) and target (y) and then split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Split the data into training and testing sets BEFORE resampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handling Imbalance with Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Original training set shape:\", y_train.value_counts())\n",
    "print(\"\\nResampled training set shape:\", pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training data is perfectly balanced, with an equal number of fraud and legitimate transaction samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model on the balanced data\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the original, imbalanced test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Legitimate', 'Fraud'], yticklabels=['Legitimate', 'Fraud'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Legitimate (0)', 'Fraud (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction probabilities for the positive class (fraud)\n",
    "y_scores = model.decision_function(X_test)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "avg_precision = average_precision_score(y_test, y_scores)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.step(recall, precision, where='post', label=f'AP={avg_precision:0.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "This notebook demonstrated how to approach a highly imbalanced classification problem. By using **Random Undersampling**, we were able to train a model that, while having a high number of false positives (low precision), achieves a **high recall** for the fraud class. \n",
    "\n",
    "In a real-world fraud detection system, a high recall is often prioritized. It's generally better to flag a legitimate transaction for review (a false positive) than to miss a fraudulent one (a false negative). The Precision-Recall curve clearly shows this trade-off. Our model can identify over 90% of fraudulent transactions, which is a strong result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
