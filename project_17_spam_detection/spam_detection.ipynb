{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "This notebook builds a spam detection model using the 20 Newsgroups dataset from `scikit-learn`. We will treat some newsgroup categories as 'ham' (not spam) and others as 'spam' to create a binary classification problem. The project involves text preprocessing, feature extraction using TF-IDF, and training a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "\n",
    "# Define the categories for 'ham' and 'spam'\n",
    "ham_categories = ['rec.sport.baseball', 'sci.space']\n",
    "spam_categories = ['talk.politics.guns', 'misc.forsale']\n",
    "\n",
    "# Load the datasets\n",
    "ham_train = fetch_20newsgroups(subset='train', categories=ham_categories, shuffle=True, random_state=42)\n",
    "spam_train = fetch_20newsgroups(subset='train', categories=spam_categories, shuffle=True, random_state=42)\n",
    "\n",
    "ham_test = fetch_20newsgroups(subset='test', categories=ham_categories, shuffle=True, random_state=42)\n",
    "spam_test = fetch_20newsgroups(subset='test', categories=spam_categories, shuffle=True, random_state=42)\n",
    "\n",
    "# Combine the data\n",
    "X_train = ham_train.data + spam_train.data\n",
    "y_train = np.concatenate([np.zeros(len(ham_train.data)), np.ones(len(spam_train.data))])\n",
    "\n",
    "X_test = ham_test.data + spam_test.data\n",
    "y_test = np.concatenate([np.zeros(len(ham_test.data)), np.ones(len(spam_test.data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize and train the Multinomial Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))\n",
    "print('\\nConfusion Matrix:')\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "The Multinomial Naive Bayes model achieved excellent performance in classifying the selected newsgroup posts as 'spam' or 'ham'. The high accuracy, precision, and recall scores demonstrate the effectiveness of using TF-IDF for feature extraction in text classification tasks. The model is highly capable of distinguishing between the different categories of text data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
